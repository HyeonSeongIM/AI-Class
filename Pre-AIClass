인공지능 기초를 위한 FAQ

1. 인공지능에서 지능에 해당하는 기능은 무엇인가?

사람의 지능과 같은 의미, Ai 에서 반자동적으로 학습을 할 수 있는 기능

2. 인공지능의 종류 3가지에 대해서 설명하시오 (지도학습, 반지도학습, 강화학습)

지도학습이란 정답이 있는 데이터를 활용해 학습
예시) 분류_classfication, 회귀_regression

비지도학습이란 지도 학습과는 달리 정답 라벨이 없는 데이터를 비슷한 특징끼리 군집화 하여 새로운 데이터에 대한 결과를 예측하는 방법을 비지도학습 이라고 합니다.
예시) 클러스터링_clustering

강화학습이란 행동 심리학에서 나온 이론으로 분류할 수 있는 데이터가 존재하는 것도 아니고 데이터가 있어도 정답이 따로 정해져 있지 않으며 
자신이 한 행동에 대해 보상(reward)를 받으며 학습하는 것을 말합니다.
예시) 알파고

3. 전통적인 프로그래밍 방법과 인공지능 프로그램의 차이점은 무엇인가?
전통적인 프로그래밍은 입력값과 식으로 출력값을 반환해내는 반면
인공지능 프로그램은 입력식과 출력값으로 식을 반환해낸다.

4. 딥러닝과 머신러닝의 차이점은 무엇인가?
머신 러닝은 알고리즘을 사용하여 데이터를 구문 분석하고 해당 데이터에서 학습하며, 학습한 내용에 따라 정보에 근거한 결정을 내립니다. 
딥 러닝은 알고리즘을 계층으로 구성하여 자체적으로 배우고 지능적인 결정을 내릴 수 있는 '인공 신경망'을 만듭니다.

5. Classification과 Regression의 주된 차이점은?
Classification과 Regression의 주된 차이는 classification의 경우 남성 vs 여성, 참 vs 거짓 등의 discrete한 value를 예측/분류하는데 사용되고, 
regression은 가격, 급여, 나이 등과 같은 continuous한 value를 예측하는데 사용된다는 점이다.

6. 머신러닝에서 차원의 저주(curse of dimensionality)란?
데이터 학습을 위해 차원이 증가하면서 학습데이터 수가 차원의 수보다 적어져 성능이 저하되는 현상
차원이 증가할수록 개별 차원 내의 학습 데이터수가 적어지는 현상
해결법: 차원을 줄이거나 데이터를 많이 획득

7. Dimensionality Reduction는 왜 필요한가?
차원축소의 목적(필요성)
정보 손실의 최소화하여 가능한 많은 정보를 포함하고 데이터 설명에 중요한 변수만 선택합니다.
어떤 목적에 따라 데이터의 양을 줄이는 방법

8. Ridge와 Lasso의 공통점과 차이점? (Regularization, 규제 , Scaling)
선형 회귀 모델에 규제를 추가한 모델을 릿지(ridge) 와 라쏘(lasso) 라고 부른다. 두 모델은 규제를 가하는 방법이 다르다. 
릿지는 계수를 제곱한 값을 기준으로 규제를 적용하고 라쏘는 계수의 절댓값을 기준으로 규제를 적용한다

9. Overfitting vs. Underfitting
Overfitting은 데이터의 양이 많아 값들이 표준에 미치지 못한 상태 -> 데이터의 양을 줄이기, 차원을 높이기
Underfitting은 데이터의 양이 적어 값들이 표준에 미치치 못한 상태 -> 데이터의 양을 늘리기

10. Feature Engineering과 Feature Selection의 차이점은?
Feature Engineering은 모델 정확도를 높이기 위해서 주어진 데이터를
예측 모델의 문제를 잘 표현할 수 있는 features로 변형시키는 과정이다.
'머신러닝 알고리즘을 작동하기 위해 데이터의 도메인 지식을 활용해 feature를 만드는 과정'이라고 할 수도 있다.

Feature Selection은 관련없거나 중복되는 Feature들을 필터링하고 간결한 subset을 만드는 과정이다.

11. 전처리(Preprocessing)의 목적과 방법? (노이즈, 이상치, 결측치)
분석 결과의 신뢰성을 결정짓는 과정이다.
전체 작업 시간으로 보면 60~70% 이상이 소요될 정도로 중요한 과정이다.
데이터 전처리가 잘 안 된 경우라면 원하는 분석 결과가 나오지 않거나 엉뚱한 분석 결과가 도출되기도 한다.
데이터 전처리 과정
데이터셋 확인 : 변수 유형(독립/종속, 범주형/연속형, 문자/숫자), 변수 간의 관계 및 분포
결측값과 이상값 처리
feature engineering : 기존 변수 사용, 정보 추가, 기존 데이터 보완


12. EDA(Explorary Data Analysis)란? 데이터의 특성 파악(분포, 상관관계)
수집한 데이터가 들어왔을 때, 이를 다양한 각도에서 관찰하고 이해하는 과정 
이 과정의 목표는 서로 의미있는 상관관계를 파악하는 것
데이터 분포 및 값을 검토함으로써 데이터가 표현하는 현상을 더 잘 이해하기 쉽게 해준다.

13. 회귀에서 절편과 기울기가 의미하는 바는? 딥러닝과 어떻게 연관되는가?
절편: 회귀선이 y축과 만나는 지점
기울기: 회귀선이 x축과 만나는 지점

딥러닝에서 가중치로 기울기와 유사하고 편향은 절편과 유사하다

14. Activation function 함수를 사용하는 이유? Softmax, Sigmoid 함수의 차이는?
신경망이 단순히 선형 관계만 학습하게 두지 않고, 
비선형성을 도입하여 복잡한 데이터 패턴을 학습할 수 있게 도와줍니다. 
(비선현성, 계층적표현, 경사하강법을 통한 학습 기능)

Softmax는 이진 분류에 적합, 각 분류의 확률이 나옴
Sigmoid는 다중 클래스 분류에 적합, 총 확률의 합이 1로 내려짐


15. Forward propagation, Backward propagation이란?
Forward propagation(순전파)은 입력 데이터를 신경망의 각 계층을 통해 전달하며 최종 출력을 계산하는 과정입니다. 
이때, 입력은 가중치(weight)와 편향(bias)을 거쳐 각 층에서 변환되며, 
활성화 함수(activation function)를 통해 비선형성을 적용하여 다음 층으로 전달됩니다.

Backward propagation은 순전파를 통해 계산된 예측값과 실제 값 사이의 오차를 바탕으로 신경망의 가중치와 편향을 업데이트하는 과정입니다.
이 과정은 경사 하강법(Gradient Descent)을 사용하여 손실 함수의 기울기(gradient)를 계산하고, 그 기울기를 통해 가중치와 편향을 조정합니다. 
이를 통해 모델이 예측 오류를 줄일 수 있도록 학습합니다.

Forward Propagation은 신경망의 예측을 계산하는 과정이고, Backward Propagation은 그 예측 결과를 바탕으로 신경망을 학습시키는 과정입니다.
순전파에서 예측값을 얻고, 역전파에서 그 예측값의 오차를 이용해 가중치를 업데이트합니다.

16. 손실함수란 무엇인가? 가장 많이 사용하는 손실함수 4가지 종류는?
머신러닝과 딥러닝 모델의 예측값과 실제값 사이의 차이를 측정하는 함수입니다. 
손실 함수가 작아질수록 모델의 예측이 실제값에 더 가까워진다는 것을 의미합니다.

1) Mean Squred Error (MSE, 평균 제곱 오차)
회귀 문제에서 주로 사용되며, 실제값과 예측값 사이의 차이의 제곱을 평균한 값입니다.

2) Mean Abosolute Eroor (MAE, 평균 절대 오차)
실제값과 예측값 사이의 차이의 절대값을 평균한 값입니다.

3) Cross-Entropy Loss (교차 엔트로피 손실)
분류 문제에서 주로 사용되는 손실 함수로, 예측 확률 분포와 실제 클래스 분포 간의 차이를 측정합니다.

4) Hinge Loss (힌지 손실)
주로 서포트 벡터 머신(SVM)에서 사용되는 손실 함수로, 분류 문제에서 사용되며 예측값과 실제값 사이의 마진을 계산합니다.

회귀 문제에서는 MSE 또는 MAE를 주로 사용합니다. MSE는 큰 오차에 더 민감하게 반응하고, MAE는 모든 오차를 동일하게 처리합니다.
분류 문제에서는 Cross-Entropy가 가장 많이 사용됩니다. 다중 클래스 분류의 경우 Softmax와 결합하여 사용되며, 이진 분류의 경우 Sigmoid와 결합하여 사용됩니다.

17. 옵티마이저(optimizer)란 무엇일까? 옵티마이저와 손실함수의 차이점은?
딥러닝 모델이 주어진 데이터를 학습하는 과정에서 가중치와 편향을 효율적으로 업데이트하는 알고리즘입니다.

손실 함수는 모델이 예측한 값과 실제 값 사이의 차이를 나타내며, 이 차이를 바탕으로 모델의 성능을 평가합니다.
옵티마이저는 손실 함수가 제공한 정보를 기반으로 모델의 파라미터를 조정하여 손실 값을 최소화하는 방향으로 학습을 진행합니다. 
손실 함수가 기울기를 제공하면, 옵티마이저는 그 기울기를 사용하여 파라미터 업데이트를 수행합니다.

18. 경사하강법 의미는? (확률적 경사하강법, 배치 경사하강법, 미치 배치경사하강법)
머신러닝과 딥러닝에서 손실 함수를 최소화하기 위해 모델의 가중치와 편향을 업데이트하는 최적화 알고리즘입니다. 
손실 함수의 기울기(경사)를 따라 가장 낮은 지점(최적점)을 찾아가는 과정으로, 손실 함수의 값이 가장 작아지는 방향으로 파라미터를 조정하여 모델을 학습시킵니다.

1) 배치 경사 하강법(Batch Gradient Descent)
전체 데이터셋을 한 번에 사용하여 기울기를 계산하고, 그 기울기를 기반으로 가중치를 업데이트합니다.

2) 확률적 경사 하강법(Stochastic Gradient Descent, SGD)
매번 하나의 데이터 샘플에 대해 기울기를 계산하고 가중치를 업데이트합니다. 

3) 미니 배치 경사 하강법(Mini-batch Gradient Descent)
전체 데이터를 사용하는 배치 경사 하강법과 하나의 샘플만 사용하는 SGD의 절충안으로, 
전체 데이터셋을 여러 개의 작은 배치로 나누어, 각 배치에 대해 기울기를 계산하고 가중치를 업데이트합니다.

19. 교차검증, K-fold 교차검증의 의미와 차이
머신러닝에서 모델의 성능을 평가하고 과적합(overfitting)을 방지하기 위해 데이터를 여러 번 나누어 모델을 학습하고 평가하는 방법입니다. 
모델이 학습한 데이터에 과도하게 적합되지 않도록 데이터를 다양한 방식으로 나누어 반복적으로 평가하여 일반화 성능을 높이는 데 사용됩니다.

K-fold 교차검증은 교차검증의 한 방법으로, 데이터를 K개의 부분(fold)으로 나누어 각각의 폴드를 테스트셋으로 사용하고 나머지 K-1개의 폴드를 학습셋으로 사용하는 방식입니다. 
이를 K번 반복하여 모든 폴드가 한 번씩 테스트셋으로 사용되도록 합니다.

기본 교차검증은 데이터를 한 번 학습셋과 테스트셋으로 나누어 평가하는 방식으로, 단일 평가로 끝나는 경우가 많습니다. 이는 특정 데이터 분할에 따라 성능이 좌우될 수 있습니다.
K-fold 교차검증은 데이터를 K개의 폴드로 나누어 K번 학습과 평가를 반복하여, 모든 데이터가 학습과 평가에 사용되도록 합니다. 평가의 신뢰성이 높고, 더 정확한 모델 성능 측정이 가능합니다.

20. 하이퍼파라미터 튜닝이란 무엇인가?
머신러닝 및 딥러닝 모델의 성능을 최적화하기 위해 모델 외부에서 설정해야 하는 매개변수(하이퍼파라미터) 값을 조정하는 과정입니다. 
하이퍼파라미터는 모델 학습 과정에서 직접 학습되지 않으며, 사람이 사전에 설정해야 합니다.

모델 성능 최적화: 잘못된 하이퍼파라미터 선택은 모델 성능을 크게 저하시킬 수 있습니다.
예를 들어 학습률이 너무 크면 모델이 수렴하지 않고 발산할 수 있고, 너무 작으면 학습 속도가 느리며 최적점에 도달하지 못할 수 있습니다.
과적합 방지: 하이퍼파라미터는 모델의 복잡도를 조절할 수 있어 과적합이나 과소적합을 방지하는 데 중요한 역할을 합니다.


21. CNN의 합성곱의 역활은?
입력 데이터의 중요한 패턴을 추출하는 것입니다. 합성곱 연산은 이미지나 신호 데이터에서 지역적 특징을 감지하고, 그 특징을 기반으로 더 복잡한 패턴을 인식하는 데 기여합니다.

1) 특징 추출 : 입력 데이터에서 중요한 패턴이나 특징을 추출

2) 지역적 연결 : 지역적, 부분적으로 처리

3) 파라미터 공유 : 입력 데이터의 모든 위치에서 동일하게 적용

22. CNN의 풀링층의 역활은?
입력 데이터의 공간 크기를 줄이기 위한 연산으로, 합성곱 층에서 추출한 특징 맵을 축소하면서 계산량을 줄이고, 과적합(overfitting)을 방지하는 데 도움을 줍니다

Max Pooling: 작은 영역에서 최대값을 취해 중요한 특징만 남기고 불필요한 정보를 제거합니다.
Average Pooling: 작은 영역에서 평균값을 취해 데이터를 축소합니다.

1) 데이터 크기 축소: 특징 맵의 크기를 줄여 계산 비용을 감소시킵니다.
2) 불변성 강화: 입력 데이터의 작은 변화(예: 위치나 회전)에 대한 불변성을 강화하여, 모델이 중요한 특징을 더 잘 인식할 수 있게 합니다.
3) 과적합 방지: 데이터를 축소함으로써 파라미터 수를 줄이고, 과적합을 줄이는 데 기여합니다.

23. CNN의 Dense Layer의 역활은?

CNN에서 마지막 단계에 위치하여 추출된 특징을 종합하여 최종 결론을 내리는 역할을 합니다. 입력으로 받은 모든 뉴런이 다음 층의 모든 뉴런과 연결되어 있어, 이미지의 고수준 특징을 바탕으로 분류나 예측을 수행합니다.

1) 특징 종합: 풀링층과 합성곱층에서 추출한 특징들을 종합하여, 학습된 패턴을 기반으로 최종 출력을 계산합니다.

2) 분류 및 예측: 최종적으로 분류 문제에서는 각 클래스에 대한 확률을 계산하고, 회귀 문제에서는 값을 예측하는 데 사용됩니다.

24. CNN의 stride, filter의 역활? 필터의 가중치는 어떻게 결정되는가?
1) 필터를 적용할 때 한 번에 이동하는 간격을 의미합니다. 스트라이드가 1이면 필터가 한 픽셀씩 이동하고, 스트라이드가 2면 필터가 두 픽셀씩 이동합니다.

출력 크기 조절: 스트라이드를 크게 하면 필터가 한 번에 많은 픽셀을 건너뛰므로 출력 크기가 작아지게 됩니다. 이는 데이터 크기를 줄여 계산 속도를 높이는 데 기여합니다.
특징 집중: 스트라이드를 조정하여 모델이 데이터의 전역적(global) 패턴보다 국소적(local) 패턴에 집중할 수 있게 하거나, 반대로 더 넓은 범위를 커버할 수 있게 합니다.

2) CNN에서 가장 중요한 요소로, 작은 행렬로 표현되며 입력 데이터에서 특정 패턴을 추출하는 역할을 합니다. 
필터는 이미지 데이터에서 엣지, 모서리, 질감과 같은 저수준 특징을 감지합니다. 필터는 여러 개 사용할 수 있으며, 각 필터는 다른 특징을 감지하도록 학습됩니다.

특징 감지: 필터는 합성곱 연산을 통해 입력 데이터에서 특정 패턴을 추출합니다. 이 패턴은 이미지의 특정 부분에서 발생하는 엣지나 모서리 같은 정보일 수 있습니다.
특징 맵 생성: 각 필터는 입력 데이터에 대해 합성곱 연산을 수행한 후, 특징 맵(feature map)을 생성합니다. 필터가 많을수록 다양한 특징 맵을 생성할 수 있습니다.

3) 학습 과정에서 자동으로 결정됩니다. 필터는 초기화될 때 무작위 값으로 설정되지만, 역전파(Backpropagation)와 경사하강법(Gradient Descent)을 통해 업데이트됩니다.

필터 가중치 학습 과정)

초기화: 필터의 가중치는 무작위 값으로 초기화됩니다.
순전파(Forward Propagation): 필터를 사용해 입력 이미지에 합성곱 연산을 수행하여 특징 맵을 계산합니다.
손실 계산: 예측 결과와 실제 결과 간의 차이를 손실함수를 통해 계산합니다.
역전파(Backpropagation): 손실값을 최소화하기 위해, 필터의 가중치에 대해 기울기(Gradient)를 계산합니다.
가중치 업데이트: 경사하강법을 통해 필터 가중치를 업데이트하여, 손실을 줄이는 방향으로 필터가 학습됩니다.
반복: 이 과정을 반복하면서 필터는 입력 데이터에서 더 유의미한 패턴을 감지하도록 학습됩니다.

25. RNN(Recurrent Neural Network)을 사용하는 이유와 한계점은?
RNN을 사용하는 이유
순차적 데이터 처리: RNN은 입력 데이터의 순서를 고려하여 각 단계의 정보를 기억하고 처리합니다. 이는 문장이나 음성처럼 시간적 순서가 중요한 데이터에서 유용합니다.
장기 의존성 학습: RNN은 현재 입력과 이전 상태를 결합하여 시퀀스 데이터의 장기 의존성을 학습할 수 있습니다. 이는 문맥을 파악하거나 시계열의 패턴을 분석하는 데 필요합니다.
가변 길이 시퀀스 처리: RNN은 입력 데이터의 길이에 상관없이 처리할 수 있어, 길이가 다양한 시퀀스 데이터에 적합합니다.

RNN의 한계점
장기 의존성 문제(Long-Term Dependency): RNN은 오랜 시간 간격이 있는 정보 간의 관계를 학습하기 어려운 경우가 많습니다. 이는 정보를 기억하고 유지하는 데 어려움을 겪는 문제입니다.
기울기 소실(Vanishing Gradient) 문제: RNN은 역전파 과정에서 기울기가 점점 작아지는 기울기 소실 문제를 겪을 수 있습니다. 이는 모델이 장기 의존성을 학습하지 못하게 만들 수 있습니다.
기울기 폭발(Exploding Gradient) 문제: 기울기가 너무 커지는 기울기 폭발 문제도 발생할 수 있으며, 이는 학습을 불안정하게 만듭니다.
병렬 처리의 어려움: RNN은 순차적으로 데이터를 처리하기 때문에 병렬 처리가 어려워 학습 속도가 느릴 수 있습니다.


26. LSTM(Long Short-Term Memory)을 사용하는 이유와 한계점은?
LSTM을 사용하는 이유
장기 의존성 학습: LSTM은 내부 상태를 통해 장기적인 의존성을 학습할 수 있습니다. 이는 셀 상태(cell state)와 게이트(gate) 구조를 사용하여 장기 정보를 효과적으로 유지하고 전달합니다.
기울기 소실 문제 해결: LSTM은 기울기 소실 문제를 완화하여, 긴 시퀀스에서도 안정적으로 학습할 수 있습니다. 이는 LSTM의 구조가 기울기를 더 오랫동안 유지할 수 있도록 돕기 때문입니다.
기울기 폭발 문제 완화: LSTM은 셀 상태와 게이트 구조로 인해 기울기 폭발 문제를 부분적으로 완화할 수 있습니다.

LSTM의 한계점
모델의 복잡성: LSTM은 많은 파라미터와 복잡한 구조를 가지므로, 연산 자원이 많이 소모될 수 있습니다.
훈련 시간: LSTM의 복잡한 구조로 인해 훈련 시간이 길어질 수 있습니다.
적용 범위의 한계: 모든 문제에 LSTM이 최적이진 않으며, 특정 문제에서는 다른 모델이 더 효과적일 수 있습니다.


27. GRU(Gated Recurrent Unit)을 사용하는 이유와 차별성은?
GRU를 사용하는 이유
간단한 구조: GRU는 LSTM에 비해 더 간단한 구조를 가지고 있으며, 게이트가 적고 파라미터 수가 적어 계산이 더 효율적입니다.
학습 속도: GRU는 구조가 간단하기 때문에 학습 속도가 LSTM보다 빠를 수 있습니다. 이는 훈련 시간이 단축될 수 있음을 의미합니다.
성능: 많은 경우 GRU는 LSTM과 비슷한 성능을 보이며, 복잡한 문제를 처리할 수 있습니다.

GRU와 LSTM의 차별성
구조의 단순성: GRU는 LSTM에 비해 셀 상태와 게이트가 적어 구조가 더 단순합니다. GRU는 업데이트 게이트와 리셋 게이트만을 사용하여 정보를 조절합니다.
셀 상태: LSTM은 별도의 셀 상태(cell state)를 유지하지만, GRU는 셀 상태 없이 은닉 상태(hidden state)만을 사용하여 정보를 전달합니다.
파라미터 수: GRU는 LSTM보다 적은 수의 파라미터를 가지므로, 메모리 사용량이 적고 계산이 더 효율적입니다.



28. 결정트리에서 불순도(Impurity) – 지니 계수(Gini Index)란 무엇인가?
결정트리에서 사용되는 불순도 지표 중 하나
지니 계수는 데이터 집합의 불순도를 측정하는 지표로, 특정 노드에서의 클래스 불균형을 나타냅니다. 값이 낮을수록 노드가 더 순수하다는 것을 의미합니다.

분할 기준: 결정트리는 지니 계수를 사용하여 데이터를 분할할 때, 각 노드에서 지니 계수를 최소화하는 방향으로 데이터를 나눕니다. 
즉, 지니 계수가 낮은 노드를 우선적으로 선택하여 분할합니다.
효율성: 지니 계수는 계산이 간단하고 효율적이어서 결정트리 모델에서 널리 사용됩니다. 
또한, 지니 계수는 정보 이득(Information Gain)과 유사한 개념을 가지고 있으며, 데이터의 불순도를 잘 측정합니다.

29. 앙상블이란 무엇인가?
여러 개의 모델을 결합하여 더 나은 성능을 달성하는 기법입니다. 단일 모델이 갖는 한계를 극복하고, 다양한 모델의 강점을 모아서 예측의 정확도를 향상시키는 데 사용됩니다.

다양성: 서로 다른 모델을 결합하여 예측의 다양성을 높입니다. 다양한 모델이 서로 다른 방식으로 문제를 해결하므로, 이들을 결합함으로써 오차를 줄일 수 있습니다.
강화된 성능: 개별 모델보다 앙상블 모델이 더 나은 예측 성능을 가지는 경우가 많습니다. 이는 모델이 갖는 편향(bias)과 분산(variance)을 줄이는 데 기여합니다.


30. 부트 스트랩핑(bootstraping)이란 무엇인가?
재표본화(Resampling) 기법으로, 주어진 데이터 집합에서 중복을 허용하여 여러 개의 샘플을 랜덤으로 추출하여 새로운 데이터 집합을 생성하는 방법입니다. 
이 데이터 집합들은 원본 데이터 집합의 통계적 특성을 반영하며, 모델 평가나 통계적 추정에 사용됩니다.

재표본화: 원본 데이터 집합에서 랜덤하게 샘플을 선택하여 새로운 데이터 집합을 생성합니다. 이 과정에서 중복된 샘플이 포함될 수 있습니다.
통계적 추정: 부트 스트랩핑은 **신뢰 구간(confidence interval)**이나 **표준 오차(standard error)**를 추정하는 데 사용될 수 있습니다.
모델 평가: 모델의 성능을 평가할 때 데이터의 분포를 반영한 여러 샘플을 생성하여, 모델의 일반화 성능을 보다 정확히 평가할 수 있습니다.

31. 배깅(Bagging)이란 무엇인가?
앙상블 학습 기법 중 하나로, 부트 스트랩핑을 사용하여 여러 개의 모델을 학습시키고, 이들의 예측 결과를 결합하여 예측 성능을 향상시키는 방법

부트 스트랩 샘플링: 원본 데이터 집합에서 여러 개의 부트 스트랩 샘플을 생성합니다. 각 샘플은 중복을 허용하여 추출된 데이터로 구성됩니다.
모델 학습: 각 부트 스트랩 샘플을 사용하여 개별 모델을 학습시킵니다.
예측 집계: 각 모델의 예측 결과를 평균(회귀의 경우) 또는 다수결(voting, 분류의 경우)로 결합하여 최종 예측 결과를 생성합니다.

32. 주성분 분석(PCA) 이란 무엇인가?
차원 축소 기법으로, 데이터의 분산(variance)을 최대화하는 방향으로 새로운 축을 찾는 방법입니다. 
이는 고차원 데이터를 저차원으로 변환하여 정보의 손실을 최소화하며, 데이터의 주요 구조를 분석하는 데 도움을 줍니다.

33. Dense Layer란 무엇인가?
모든 뉴런이 서로 연결된 완전 연결층으로, 입력 데이터의 특징을 종합하여 예측 결과를 생성합니다.

뉴런 연결: 각 뉴런이 다음 층의 모든 뉴런과 연결되어 있어, 입력 데이터의 모든 정보가 다음 층으로 전달됩니다.
가중치와 바이어스: 각 연결에는 가중치(weight)가 있으며, 각 뉴런에는 바이어스(bias)가 추가됩니다. 이를 통해 모델은 데이터의 복잡한 패턴을 학습할 수 있습니다.
활성화 함수: Dense Layer는 주로 활성화 함수(activation function)를 사용하여 뉴런의 출력을 비선형적으로 변환합니다. 이는 모델이 더 복잡한 관계를 학습할 수 있게 합니다.

